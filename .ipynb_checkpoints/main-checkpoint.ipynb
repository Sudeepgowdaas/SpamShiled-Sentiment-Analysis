{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90885842",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyC4Df6QGnSRbaONeMRP0fhDt4czdQFQJ-k\"\n",
    "url = \"https://www.youtube.com/watch?v=lBWDMQ8L3rc&t=14s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99fc240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted video ID: lBWDMQ8L3rc\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_video_id(url):\n",
    "    \"\"\"\n",
    "    Extract the YouTube video ID from a URL.\n",
    "    Supports both short and long YouTube URLs.\n",
    "    \"\"\"\n",
    "    # Regex pattern to extract video ID\n",
    "    pattern = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
    "    match = re.match(pattern, url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "video_id = extract_video_id(url)\n",
    "print(\"Extracted video ID:\", video_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03dc748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               comment\n",
      "0    nattu kaka speek a point uske dil ka size bada...\n",
      "1                              ladko ne toh pap kiya h\n",
      "2                                  daya jethalal dalal\n",
      "3    pura episode maadrchod daya ke baje se bhagana...\n",
      "4    betiya hi sab keshytro main hai betiyose hi gh...\n",
      "..                                                 ...\n",
      "478                                          babita ji\n",
      "479                              amazing funny episode\n",
      "480                      subh asubh kuch nahi hota hai\n",
      "481                                keya pagel hai deba\n",
      "482                            funny amazing fantastic\n",
      "\n",
      "[483 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "def extract_video_id(url):\n",
    "    \"\"\"\n",
    "    Extract the YouTube video ID from a URL.\n",
    "    Supports both short and long YouTube URLs.\n",
    "    \"\"\"\n",
    "    pattern = r'(?:https?:\\/\\/)?(?:www\\.)?(?:youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})'\n",
    "    match = re.match(pattern, url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_video_comments(video_id, api_key):\n",
    "    # Build the YouTube service\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    # Initialize variables\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        # Request to get comments\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            pageToken=next_page_token,\n",
    "            maxResults=100,  # Max is 100\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Parse the response\n",
    "        for item in response[\"items\"]:\n",
    "            comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(comment)\n",
    "\n",
    "        # Check for next page\n",
    "        next_page_token = response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # Remove non-ASCII characters\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "\n",
    "def remove_digits(text):\n",
    "    # Remove numeric digits\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters except whitespace\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def normalize_case(text):\n",
    "    # Normalize text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = remove_urls(text)\n",
    "    # Remove non-ASCII characters\n",
    "    text = remove_non_ascii(text)\n",
    "    # Remove numeric digits\n",
    "    text = remove_digits(text)\n",
    "    # Remove special characters except whitespace\n",
    "    text = remove_special_characters(text)\n",
    "    # Normalize case\n",
    "    text = normalize_case(text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "video_id = extract_video_id(url)\n",
    "if video_id:\n",
    "    comments = get_video_comments(video_id, api_key)\n",
    "    cleaned_comments = [clean_text(comment) for comment in comments]\n",
    "    \n",
    "    i = 0\n",
    "    filtered_comments = []\n",
    "\n",
    "    for comment in cleaned_comments:\n",
    "        if len(comment) > 5:\n",
    "            filtered_comments.append(comment)\n",
    "\n",
    "    df_filtered_comments = pd.DataFrame(filtered_comments, columns=['comment'])\n",
    "\n",
    "    print(df_filtered_comments)\n",
    "            \n",
    "else:\n",
    "    print(\"Invalid YouTube URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfee8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  spam_prediction\n",
      "0  nattu kaka speek a point uske dil ka size bada...                1\n",
      "1                            ladko ne toh pap kiya h                0\n",
      "2                                daya jethalal dalal                0\n",
      "3  pura episode maadrchod daya ke baje se bhagana...                0\n",
      "4  betiya hi sab keshytro main hai betiyose hi gh...                1\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load('spam_detection_model.pkl')\n",
    "\n",
    "# Define cleaning functions\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    # Remove non-ASCII characters\n",
    "    return ''.join(char for char in text if ord(char) < 128)\n",
    "\n",
    "def remove_digits(text):\n",
    "    # Remove numeric digits\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # Remove special characters except whitespace\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def normalize_case(text):\n",
    "    # Normalize text to lowercase\n",
    "    return text.lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = remove_urls(text)\n",
    "    # Remove non-ASCII characters\n",
    "    text = remove_non_ascii(text)\n",
    "    # Remove numeric digits\n",
    "    text = remove_digits(text)\n",
    "    # Remove special characters except whitespace\n",
    "    text = remove_special_characters(text)\n",
    "    # Normalize case\n",
    "    text = normalize_case(text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to the 'comment' column\n",
    "df_filtered_comments['comment'] = df_filtered_comments['comment'].apply(clean_text)\n",
    "\n",
    "# Predict using the loaded model\n",
    "new_predictions = model.predict(df_filtered_comments['comment'])\n",
    "\n",
    "# Add predictions to the new data\n",
    "df_filtered_comments['spam_prediction'] = new_predictions\n",
    "\n",
    "print(df_filtered_comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca7f305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>spam_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ladko ne toh pap kiya h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daya jethalal dalal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pura episode maadrchod daya ke baje se bhagana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>like those who are watching this episode in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>daya bhabhi notty ho rahee hoo notty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  spam_prediction\n",
       "1                            ladko ne toh pap kiya h                0\n",
       "2                                daya jethalal dalal                0\n",
       "3  pura episode maadrchod daya ke baje se bhagana...                0\n",
       "6        like those who are watching this episode in                0\n",
       "8               daya bhabhi notty ho rahee hoo notty                0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonspam_comments = df_filtered_comments[df_filtered_comments['spam_prediction']==0]\n",
    "\n",
    "df_nonspam_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93182c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonspam_comments = df_nonspam_comments[['comment']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b8e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comment  sentiment_prediction\n",
      "0                             ladko ne toh pap kiya h                     1\n",
      "1                                 daya jethalal dalal                     2\n",
      "2   pura episode maadrchod daya ke baje se bhagana...                     2\n",
      "3         like those who are watching this episode in                     1\n",
      "4                daya bhabhi notty ho rahee hoo notty                     2\n",
      "5                                 daya behn daya beti                     2\n",
      "6        gada family ki new planning for second child                     1\n",
      "7         aaj bhi esa he hota hai kahi kahi family me                     1\n",
      "8       daya overacting karti thi sai hat gyi show se                     2\n",
      "9                agaya potoalal ki shadi tho nahi hui                     1\n",
      "10                                         pagal daya                     2\n",
      "11                  daya second child ke full mood me                     2\n",
      "12                             my sankari kar lo yaar                     1\n",
      "13  sabjee wali ki makeup society me rehne wale lo...                     2\n",
      "14      har har mahadev jay shri ram jay shri krishna                     1\n",
      "15                   all gokuldham ladies are so cute                     2\n",
      "16                                  moye moye poptlal                     1\n",
      "17  sare gokuldhamwale panauti hai sadi bol bol ke...                     1\n",
      "18                                           popatlal                     1\n",
      "19                         yeh tho family show tha na                     1\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "sentiment_model = joblib.load('sentiment_detection_model.pkl')\n",
    "\n",
    "# Predict using the loaded model\n",
    "sentiment_predictions = sentiment_model.predict(df_nonspam_comments['comment'])\n",
    "\n",
    "# Add predictions to the new data\n",
    "df_nonspam_comments['sentiment_prediction'] = sentiment_predictions\n",
    "\n",
    "print(df_nonspam_comments.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd16696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youtube Video URL ID: lBWDMQ8L3rc\n",
      "Total Comments: 253\n",
      "Positive Comments: 24.11%\n",
      "Neutral Comments: 68.77%\n",
      "Negative Comments: 7.11%\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_nonspam_comments is your DataFrame and sentiment_prediction column is already populated\n",
    "total_comments = len(df_nonspam_comments)\n",
    "\n",
    "# Count the number of each sentiment type\n",
    "sentiment_counts = df_nonspam_comments['sentiment_prediction'].value_counts()\n",
    "\n",
    "# Calculate percentages\n",
    "positive_percentage = (sentiment_counts.get(2, 0) / total_comments) * 100\n",
    "neutral_percentage = (sentiment_counts.get(1, 0) / total_comments) * 100\n",
    "negative_percentage = (sentiment_counts.get(0, 0) / total_comments) * 100\n",
    "\n",
    "print(f\"Youtube Video URL ID: {video_id}\")\n",
    "print(f\"Total Comments: {total_comments}\")\n",
    "print(f\"Positive Comments: {positive_percentage:.2f}%\")\n",
    "print(f\"Neutral Comments: {neutral_percentage:.2f}%\")\n",
    "print(f\"Negative Comments: {negative_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa781b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
